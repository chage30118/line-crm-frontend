/**
 * å‚™ä»½ Supabase è³‡æ–™åº«
 *
 * æ­¤è…³æœ¬æœƒï¼š
 * 1. åŒ¯å‡º users å’Œ messages è¡¨çš„æ‰€æœ‰è³‡æ–™
 * 2. å„²å­˜ç‚º JSON æ ¼å¼
 * 3. å»ºç«‹æ™‚é–“æˆ³è¨˜çš„å‚™ä»½æª”æ¡ˆ
 *
 * åŸ·è¡Œæ–¹å¼ï¼šnpm run backup-db
 */

import { createClient } from '@supabase/supabase-js'
import * as dotenv from 'dotenv'
import { fileURLToPath } from 'url'
import { dirname, join } from 'path'
import fs from 'fs'

const __filename = fileURLToPath(import.meta.url)
const __dirname = dirname(__filename)

// è¼‰å…¥ç’°å¢ƒè®Šæ•¸
dotenv.config({ path: join(__dirname, '../.env') })

// åˆå§‹åŒ– Supabase å®¢æˆ¶ç«¯
const supabaseUrl = process.env.VITE_SUPABASE_URL
const supabaseKey = process.env.VITE_SUPABASE_ANON_KEY

if (!supabaseUrl || !supabaseKey) {
  console.error('âŒ éŒ¯èª¤: ç¼ºå°‘ Supabase ç’°å¢ƒè®Šæ•¸')
  process.exit(1)
}

const supabase = createClient(supabaseUrl, supabaseKey)

/**
 * å‚™ä»½å–®ä¸€è³‡æ–™è¡¨
 */
async function backupTable(tableName) {
  console.log(`\nğŸ“¦ æ­£åœ¨å‚™ä»½ ${tableName} è¡¨...`)

  let allData = []
  let from = 0
  const batchSize = 1000

  try {
    while (true) {
      const { data, error, count } = await supabase
        .from(tableName)
        .select('*', { count: 'exact' })
        .range(from, from + batchSize - 1)

      if (error) {
        throw new Error(`æŸ¥è©¢å¤±æ•—: ${error.message}`)
      }

      if (!data || data.length === 0) {
        break
      }

      allData = allData.concat(data)
      from += batchSize

      console.log(`   å·²åŒ¯å‡º ${allData.length} ç­†è³‡æ–™...`)

      if (data.length < batchSize) {
        break
      }
    }

    console.log(`âœ… ${tableName} è¡¨å‚™ä»½å®Œæˆ: å…± ${allData.length} ç­†è³‡æ–™`)
    return { success: true, data: allData, count: allData.length }
  } catch (error) {
    console.error(`âŒ ${tableName} è¡¨å‚™ä»½å¤±æ•—:`, error.message)
    return { success: false, error: error.message, data: [], count: 0 }
  }
}

/**
 * å„²å­˜å‚™ä»½æª”æ¡ˆ
 */
function saveBackupFile(tableName, data, timestamp) {
  const backupDir = join(__dirname, '../backups')

  // å»ºç«‹ backups ç›®éŒ„
  if (!fs.existsSync(backupDir)) {
    fs.mkdirSync(backupDir, { recursive: true })
  }

  const filename = `${tableName}_backup_${timestamp}.json`
  const filepath = join(backupDir, filename)

  fs.writeFileSync(filepath, JSON.stringify(data, null, 2), 'utf-8')

  console.log(`ğŸ’¾ å‚™ä»½æª”æ¡ˆå·²å„²å­˜: ${filepath}`)
  return filepath
}

/**
 * ä¸»è¦å‚™ä»½æµç¨‹
 */
async function backupDatabase() {
  const timestamp = new Date().toISOString().replace(/[:.]/g, '-').slice(0, -5)

  console.log('=' .repeat(70))
  console.log('ğŸ”„ é–‹å§‹å‚™ä»½ Supabase è³‡æ–™åº«')
  console.log('=' .repeat(70))
  console.log(`å‚™ä»½æ™‚é–“: ${new Date().toLocaleString('zh-TW')}`)
  console.log(`æ™‚é–“æˆ³è¨˜: ${timestamp}`)
  console.log()

  const backupReport = {
    timestamp: new Date().toISOString(),
    tables: {},
    files: [],
    summary: {
      totalTables: 0,
      successfulBackups: 0,
      failedBackups: 0,
      totalRecords: 0
    }
  }

  // è¦å‚™ä»½çš„è³‡æ–™è¡¨æ¸…å–®
  const tables = ['users', 'messages', 'message_limits', 'system_stats']

  // ä¾åºå‚™ä»½æ¯å€‹è³‡æ–™è¡¨
  for (const tableName of tables) {
    console.log('â”€'.repeat(70))
    const backup = await backupTable(tableName)
    backupReport.tables[tableName] = backup
    backupReport.summary.totalTables++

    if (backup.success) {
      const backupFile = saveBackupFile(tableName, backup.data, timestamp)
      backupReport.files.push(backupFile)
      backupReport.summary.successfulBackups++
      backupReport.summary.totalRecords += backup.count
    } else {
      backupReport.summary.failedBackups++
    }
  }

  // å„²å­˜å‚™ä»½å ±å‘Š
  const reportFile = join(__dirname, '../backups', `backup_report_${timestamp}.json`)
  fs.writeFileSync(reportFile, JSON.stringify(backupReport, null, 2), 'utf-8')
  backupReport.files.push(reportFile)

  // è¼¸å‡ºç¸½çµ
  console.log('\n' + '='.repeat(70))
  console.log('ğŸ“Š å‚™ä»½ç¸½çµå ±å‘Š')
  console.log('='.repeat(70))
  console.log(`ç¸½è¡¨æ•¸: ${backupReport.summary.totalTables}`)
  console.log(`æˆåŠŸå‚™ä»½: ${backupReport.summary.successfulBackups} âœ…`)
  console.log(`å¤±æ•—å‚™ä»½: ${backupReport.summary.failedBackups} ${backupReport.summary.failedBackups > 0 ? 'âŒ' : ''}`)
  console.log(`ç¸½è³‡æ–™ç­†æ•¸: ${backupReport.summary.totalRecords}`)
  console.log()
  console.log('ğŸ“ å‚™ä»½æª”æ¡ˆ:')
  backupReport.files.forEach(file => {
    const fileSize = fs.statSync(file).size
    const fileSizeMB = (fileSize / 1024 / 1024).toFixed(2)
    console.log(`   - ${file} (${fileSizeMB} MB)`)
  })

  console.log()
  console.log('='.repeat(70))

  if (backupReport.summary.failedBackups > 0) {
    console.log('âš ï¸  éƒ¨åˆ†å‚™ä»½å¤±æ•—ï¼Œè«‹æª¢æŸ¥éŒ¯èª¤è¨Šæ¯')
    console.log('å»ºè­°: è§£æ±ºå•é¡Œå¾Œé‡æ–°åŸ·è¡Œå‚™ä»½')
    process.exit(1)
  } else {
    console.log('âœ… æ‰€æœ‰è³‡æ–™å·²æˆåŠŸå‚™ä»½ï¼')
    console.log('ä¸‹ä¸€æ­¥: åŸ·è¡Œ npm run migrate-db é€²è¡Œè³‡æ–™åº«é·ç§»')
  }

  console.log('='.repeat(70))
  console.log()

  return backupReport
}

// åŸ·è¡Œå‚™ä»½
backupDatabase()
  .then(report => {
    if (report.summary.failedBackups === 0) {
      process.exit(0)
    }
  })
  .catch(err => {
    console.error('\nâŒ å‚™ä»½éç¨‹ç™¼ç”ŸéŒ¯èª¤:', err)
    process.exit(1)
  })
